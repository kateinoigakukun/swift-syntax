//// Automatically generated by generate-swiftsyntax
//// Do not edit directly!
//===----------------------------------------------------------------------===//
//
// This source file is part of the Swift.org open source project
//
// Copyright (c) 2014 - 2023 Apple Inc. and the Swift project authors
// Licensed under Apache License v2.0 with Runtime Library Exception
//
// See https://swift.org/LICENSE.txt for license information
// See https://swift.org/CONTRIBUTORS.txt for the list of Swift project authors
//
//===----------------------------------------------------------------------===//

@_spi(RawSyntax) import SwiftSyntax

extension AccessorDeclSyntax {
  enum AccessorSpecifierOptions: TokenSpecSet {
    case get
    case set
    case didSet
    case willSet
    case unsafeAddress
    case addressWithOwner
    case addressWithNativeOwner
    case unsafeMutableAddress
    case mutableAddressWithOwner
    case mutableAddressWithNativeOwner
    case _read
    case _modify
    case `init`
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.get):
        self = .get
      case TokenSpec(.set):
        self = .set
      case TokenSpec(.didSet):
        self = .didSet
      case TokenSpec(.willSet):
        self = .willSet
      case TokenSpec(.unsafeAddress):
        self = .unsafeAddress
      case TokenSpec(.addressWithOwner):
        self = .addressWithOwner
      case TokenSpec(.addressWithNativeOwner):
        self = .addressWithNativeOwner
      case TokenSpec(.unsafeMutableAddress):
        self = .unsafeMutableAddress
      case TokenSpec(.mutableAddressWithOwner):
        self = .mutableAddressWithOwner
      case TokenSpec(.mutableAddressWithNativeOwner):
        self = .mutableAddressWithNativeOwner
      case TokenSpec(._read):
        self = ._read
      case TokenSpec(._modify):
        self = ._modify
      case TokenSpec(.`init`):
        self = .`init`
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .get:
        return .keyword(.get)
      case .set:
        return .keyword(.set)
      case .didSet:
        return .keyword(.didSet)
      case .willSet:
        return .keyword(.willSet)
      case .unsafeAddress:
        return .keyword(.unsafeAddress)
      case .addressWithOwner:
        return .keyword(.addressWithOwner)
      case .addressWithNativeOwner:
        return .keyword(.addressWithNativeOwner)
      case .unsafeMutableAddress:
        return .keyword(.unsafeMutableAddress)
      case .mutableAddressWithOwner:
        return .keyword(.mutableAddressWithOwner)
      case .mutableAddressWithNativeOwner:
        return .keyword(.mutableAddressWithNativeOwner)
      case ._read:
        return .keyword(._read)
      case ._modify:
        return .keyword(._modify)
      case .`init`:
        return .keyword(.`init`)
      }
    }
  }
}

extension AsExprSyntax {
  enum QuestionOrExclamationMarkOptions: TokenSpecSet {
    case postfixQuestionMark
    case exclamationMark
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.postfixQuestionMark):
        self = .postfixQuestionMark
      case TokenSpec(.exclamationMark):
        self = .exclamationMark
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMark
      case .exclamationMark:
        return .exclamationMark
      }
    }
  }
}

extension AttributedTypeSyntax {
  enum SpecifierOptions: TokenSpecSet {
    case `inout`
    case __shared
    case __owned
    case isolated
    case _const
    case borrowing
    case consuming
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.`inout`):
        self = .`inout`
      case TokenSpec(.__shared):
        self = .__shared
      case TokenSpec(.__owned):
        self = .__owned
      case TokenSpec(.isolated):
        self = .isolated
      case TokenSpec(._const):
        self = ._const
      case TokenSpec(.borrowing):
        self = .borrowing
      case TokenSpec(.consuming):
        self = .consuming
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .`inout`:
        return .keyword(.`inout`)
      case .__shared:
        return .keyword(.__shared)
      case .__owned:
        return .keyword(.__owned)
      case .isolated:
        return .keyword(.isolated)
      case ._const:
        return .keyword(._const)
      case .borrowing:
        return .keyword(.borrowing)
      case .consuming:
        return .keyword(.consuming)
      }
    }
  }
}

extension AvailabilityConditionSyntax {
  enum AvailabilityKeywordOptions: TokenSpecSet {
    case poundAvailableKeyword
    case poundUnavailableKeyword
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.poundAvailableKeyword):
        self = .poundAvailableKeyword
      case TokenSpec(.poundUnavailableKeyword):
        self = .poundUnavailableKeyword
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .poundAvailableKeyword:
        return .poundAvailableKeyword
      case .poundUnavailableKeyword:
        return .poundUnavailableKeyword
      }
    }
  }
}

extension AvailabilityLabeledArgumentSyntax {
  enum LabelOptions: TokenSpecSet {
    case message
    case renamed
    case introduced
    case obsoleted
    case deprecated
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.message):
        self = .message
      case TokenSpec(.renamed):
        self = .renamed
      case TokenSpec(.introduced):
        self = .introduced
      case TokenSpec(.obsoleted):
        self = .obsoleted
      case TokenSpec(.deprecated):
        self = .deprecated
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .message:
        return .keyword(.message)
      case .renamed:
        return .keyword(.renamed)
      case .introduced:
        return .keyword(.introduced)
      case .obsoleted:
        return .keyword(.obsoleted)
      case .deprecated:
        return .keyword(.deprecated)
      }
    }
  }
}

extension BooleanLiteralExprSyntax {
  enum LiteralOptions: TokenSpecSet {
    case `true`
    case `false`
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.`true`):
        self = .`true`
      case TokenSpec(.`false`):
        self = .`false`
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .`true`:
        return .keyword(.`true`)
      case .`false`:
        return .keyword(.`false`)
      }
    }
  }
}

extension CanImportVersionInfoSyntax {
  enum LabelOptions: TokenSpecSet {
    case _version
    case _underlyingVersion
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(._version):
        self = ._version
      case TokenSpec(._underlyingVersion):
        self = ._underlyingVersion
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case ._version:
        return .keyword(._version)
      case ._underlyingVersion:
        return .keyword(._underlyingVersion)
      }
    }
  }
}

extension ClosureCaptureItemSpecifierSyntax {
  enum SpecifierOptions: TokenSpecSet {
    case weak
    case unowned
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.weak):
        self = .weak
      case TokenSpec(.unowned):
        self = .unowned
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .weak:
        return .keyword(.weak)
      case .unowned:
        return .keyword(.unowned)
      }
    }
  }
}

extension ClosureCaptureItemSpecifierSyntax {
  enum DetailOptions: TokenSpecSet {
    case safe
    case unsafe
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.safe):
        self = .safe
      case TokenSpec(.unsafe):
        self = .unsafe
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .safe:
        return .keyword(.safe)
      case .unsafe:
        return .keyword(.unsafe)
      }
    }
  }
}

extension ClosureParamSyntax {
  enum NameOptions: TokenSpecSet {
    case identifier
    case wildcard
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }
  }
}

extension ClosureParameterSyntax {
  enum FirstNameOptions: TokenSpecSet {
    case identifier
    case wildcard
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }
  }
}

extension ClosureParameterSyntax {
  enum SecondNameOptions: TokenSpecSet {
    case identifier
    case wildcard
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }
  }
}

extension ConstrainedSugarTypeSyntax {
  enum SomeOrAnySpecifierOptions: TokenSpecSet {
    case some
    case any
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.some):
        self = .some
      case TokenSpec(.any):
        self = .any
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .some:
        return .keyword(.some)
      case .any:
        return .keyword(.any)
      }
    }
  }
}

extension DeclModifierSyntax {
  enum NameOptions: TokenSpecSet {
    case __consuming
    case __setter_access
    case _const
    case _local
    case actor
    case async
    case borrowing
    case `class`
    case consuming
    case convenience
    case distributed
    case dynamic
    case `fileprivate`
    case final
    case indirect
    case infix
    case `internal`
    case isolated
    case lazy
    case mutating
    case nonisolated
    case nonmutating
    case open
    case optional
    case override
    case package
    case postfix
    case prefix
    case `private`
    case `public`
    case reasync
    case required
    case `static`
    case unowned
    case weak
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.__consuming):
        self = .__consuming
      case TokenSpec(.__setter_access):
        self = .__setter_access
      case TokenSpec(._const):
        self = ._const
      case TokenSpec(._local):
        self = ._local
      case TokenSpec(.actor):
        self = .actor
      case TokenSpec(.async):
        self = .async
      case TokenSpec(.borrowing):
        self = .borrowing
      case TokenSpec(.`class`):
        self = .`class`
      case TokenSpec(.consuming):
        self = .consuming
      case TokenSpec(.convenience):
        self = .convenience
      case TokenSpec(.distributed):
        self = .distributed
      case TokenSpec(.dynamic):
        self = .dynamic
      case TokenSpec(.`fileprivate`):
        self = .`fileprivate`
      case TokenSpec(.final):
        self = .final
      case TokenSpec(.indirect):
        self = .indirect
      case TokenSpec(.infix):
        self = .infix
      case TokenSpec(.`internal`):
        self = .`internal`
      case TokenSpec(.isolated):
        self = .isolated
      case TokenSpec(.lazy):
        self = .lazy
      case TokenSpec(.mutating):
        self = .mutating
      case TokenSpec(.nonisolated):
        self = .nonisolated
      case TokenSpec(.nonmutating):
        self = .nonmutating
      case TokenSpec(.open):
        self = .open
      case TokenSpec(.optional):
        self = .optional
      case TokenSpec(.override):
        self = .override
      case TokenSpec(.package):
        self = .package
      case TokenSpec(.postfix):
        self = .postfix
      case TokenSpec(.prefix):
        self = .prefix
      case TokenSpec(.`private`):
        self = .`private`
      case TokenSpec(.`public`):
        self = .`public`
      case TokenSpec(.reasync):
        self = .reasync
      case TokenSpec(.required):
        self = .required
      case TokenSpec(.`static`):
        self = .`static`
      case TokenSpec(.unowned):
        self = .unowned
      case TokenSpec(.weak):
        self = .weak
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .__consuming:
        return .keyword(.__consuming)
      case .__setter_access:
        return .keyword(.__setter_access)
      case ._const:
        return .keyword(._const)
      case ._local:
        return .keyword(._local)
      case .actor:
        return .keyword(.actor)
      case .async:
        return .keyword(.async)
      case .borrowing:
        return .keyword(.borrowing)
      case .`class`:
        return .keyword(.`class`)
      case .consuming:
        return .keyword(.consuming)
      case .convenience:
        return .keyword(.convenience)
      case .distributed:
        return .keyword(.distributed)
      case .dynamic:
        return .keyword(.dynamic)
      case .`fileprivate`:
        return .keyword(.`fileprivate`)
      case .final:
        return .keyword(.final)
      case .indirect:
        return .keyword(.indirect)
      case .infix:
        return .keyword(.infix)
      case .`internal`:
        return .keyword(.`internal`)
      case .isolated:
        return .keyword(.isolated)
      case .lazy:
        return .keyword(.lazy)
      case .mutating:
        return .keyword(.mutating)
      case .nonisolated:
        return .keyword(.nonisolated)
      case .nonmutating:
        return .keyword(.nonmutating)
      case .open:
        return .keyword(.open)
      case .optional:
        return .keyword(.optional)
      case .override:
        return .keyword(.override)
      case .package:
        return .keyword(.package)
      case .postfix:
        return .keyword(.postfix)
      case .prefix:
        return .keyword(.prefix)
      case .`private`:
        return .keyword(.`private`)
      case .`public`:
        return .keyword(.`public`)
      case .reasync:
        return .keyword(.reasync)
      case .required:
        return .keyword(.required)
      case .`static`:
        return .keyword(.`static`)
      case .unowned:
        return .keyword(.unowned)
      case .weak:
        return .keyword(.weak)
      }
    }
  }
}

extension DeclNameSyntax {
  enum DeclBaseNameOptions: TokenSpecSet {
    case identifier
    case binaryOperator
    case `init`
    case `self`
    case `Self`
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      case TokenSpec(.`init`):
        self = .`init`
      case TokenSpec(.`self`):
        self = .`self`
      case TokenSpec(.`Self`):
        self = .`Self`
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .binaryOperator:
        return .binaryOperator
      case .`init`:
        return .keyword(.`init`)
      case .`self`:
        return .keyword(.`self`)
      case .`Self`:
        return .keyword(.`Self`)
      }
    }
  }
}

extension DerivativeRegistrationAttributeArgumentsSyntax {
  enum AccessorSpecifierOptions: TokenSpecSet {
    case get
    case set
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.get):
        self = .get
      case TokenSpec(.set):
        self = .set
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .get:
        return .keyword(.get)
      case .set:
        return .keyword(.set)
      }
    }
  }
}

extension DifferentiabilityParamSyntax {
  enum ParameterOptions: TokenSpecSet {
    case identifier
    case integerLiteral
    case `self`
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.integerLiteral):
        self = .integerLiteral
      case TokenSpec(.`self`):
        self = .`self`
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .integerLiteral:
        return .integerLiteral
      case .`self`:
        return .keyword(.`self`)
      }
    }
  }
}

extension DifferentiableAttributeArgumentsSyntax {
  enum KindSpecifierOptions: TokenSpecSet {
    case _forward
    case reverse
    case _linear
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(._forward):
        self = ._forward
      case TokenSpec(.reverse):
        self = .reverse
      case TokenSpec(._linear):
        self = ._linear
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case ._forward:
        return .keyword(._forward)
      case .reverse:
        return .keyword(.reverse)
      case ._linear:
        return .keyword(._linear)
      }
    }
  }
}

extension DiscardStmtSyntax {
  enum DiscardKeywordOptions: TokenSpecSet {
    case _forget
    case discard
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(._forget):
        self = ._forget
      case TokenSpec(.discard):
        self = .discard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case ._forget:
        return .keyword(._forget)
      case .discard:
        return .keyword(.discard)
      }
    }
  }
}

extension DocumentationAttributeArgumentSyntax {
  enum LabelOptions: TokenSpecSet {
    case visibility
    case metadata
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.visibility):
        self = .visibility
      case TokenSpec(.metadata):
        self = .metadata
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .visibility:
        return .keyword(.visibility)
      case .metadata:
        return .keyword(.metadata)
      }
    }
  }
}

extension EnumCaseParameterSyntax {
  enum FirstNameOptions: TokenSpecSet {
    case identifier
    case wildcard
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }
  }
}

extension EnumCaseParameterSyntax {
  enum SecondNameOptions: TokenSpecSet {
    case identifier
    case wildcard
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }
  }
}

extension FunctionDeclSyntax {
  enum IdentifierOptions: TokenSpecSet {
    case identifier
    case binaryOperator
    case prefixOperator
    case postfixOperator
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      case TokenSpec(.prefixOperator):
        self = .prefixOperator
      case TokenSpec(.postfixOperator):
        self = .postfixOperator
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .binaryOperator:
        return .binaryOperator
      case .prefixOperator:
        return .prefixOperator
      case .postfixOperator:
        return .postfixOperator
      }
    }
  }
}

extension FunctionEffectSpecifiersSyntax {
  enum AsyncSpecifierOptions: TokenSpecSet {
    case async
    case reasync
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.async):
        self = .async
      case TokenSpec(.reasync):
        self = .reasync
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .async:
        return .keyword(.async)
      case .reasync:
        return .keyword(.reasync)
      }
    }
  }
}

extension FunctionEffectSpecifiersSyntax {
  enum ThrowsSpecifierOptions: TokenSpecSet {
    case `throws`
    case `rethrows`
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.`throws`):
        self = .`throws`
      case TokenSpec(.`rethrows`):
        self = .`rethrows`
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .`throws`:
        return .keyword(.`throws`)
      case .`rethrows`:
        return .keyword(.`rethrows`)
      }
    }
  }
}

extension FunctionParameterSyntax {
  enum FirstNameOptions: TokenSpecSet {
    case identifier
    case wildcard
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }
  }
}

extension FunctionParameterSyntax {
  enum SecondNameOptions: TokenSpecSet {
    case identifier
    case wildcard
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }
  }
}

extension IdentifierExprSyntax {
  enum IdentifierOptions: TokenSpecSet {
    case identifier
    case `self`
    case `Self`
    case `init`
    case dollarIdentifier
    case binaryOperator
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.`self`):
        self = .`self`
      case TokenSpec(.`Self`):
        self = .`Self`
      case TokenSpec(.`init`):
        self = .`init`
      case TokenSpec(.dollarIdentifier):
        self = .dollarIdentifier
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .`self`:
        return .keyword(.`self`)
      case .`Self`:
        return .keyword(.`Self`)
      case .`init`:
        return .keyword(.`init`)
      case .dollarIdentifier:
        return .dollarIdentifier
      case .binaryOperator:
        return .binaryOperator
      }
    }
  }
}

extension IdentifierPatternSyntax {
  enum IdentifierOptions: TokenSpecSet {
    case identifier
    case `self`
    case `init`
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.`self`):
        self = .`self`
      case TokenSpec(.`init`):
        self = .`init`
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .`self`:
        return .keyword(.`self`)
      case .`init`:
        return .keyword(.`init`)
      }
    }
  }
}

extension IfConfigClauseSyntax {
  enum PoundKeywordOptions: TokenSpecSet {
    case poundIfKeyword
    case poundElseifKeyword
    case poundElseKeyword
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.poundIfKeyword):
        self = .poundIfKeyword
      case TokenSpec(.poundElseifKeyword):
        self = .poundElseifKeyword
      case TokenSpec(.poundElseKeyword):
        self = .poundElseKeyword
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .poundIfKeyword:
        return .poundIfKeyword
      case .poundElseifKeyword:
        return .poundElseifKeyword
      case .poundElseKeyword:
        return .poundElseKeyword
      }
    }
  }
}

extension ImportDeclSyntax {
  enum ImportKindSpecifierOptions: TokenSpecSet {
    case `typealias`
    case `struct`
    case `class`
    case `enum`
    case `protocol`
    case `var`
    case `let`
    case `func`
    case `inout`
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.`typealias`):
        self = .`typealias`
      case TokenSpec(.`struct`):
        self = .`struct`
      case TokenSpec(.`class`):
        self = .`class`
      case TokenSpec(.`enum`):
        self = .`enum`
      case TokenSpec(.`protocol`):
        self = .`protocol`
      case TokenSpec(.`var`):
        self = .`var`
      case TokenSpec(.`let`):
        self = .`let`
      case TokenSpec(.`func`):
        self = .`func`
      case TokenSpec(.`inout`):
        self = .`inout`
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .`typealias`:
        return .keyword(.`typealias`)
      case .`struct`:
        return .keyword(.`struct`)
      case .`class`:
        return .keyword(.`class`)
      case .`enum`:
        return .keyword(.`enum`)
      case .`protocol`:
        return .keyword(.`protocol`)
      case .`var`:
        return .keyword(.`var`)
      case .`let`:
        return .keyword(.`let`)
      case .`func`:
        return .keyword(.`func`)
      case .`inout`:
        return .keyword(.`inout`)
      }
    }
  }
}

extension ImportPathComponentSyntax {
  enum NameOptions: TokenSpecSet {
    case identifier
    case binaryOperator
    case prefixOperator
    case postfixOperator
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      case TokenSpec(.prefixOperator):
        self = .prefixOperator
      case TokenSpec(.postfixOperator):
        self = .postfixOperator
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .binaryOperator:
        return .binaryOperator
      case .prefixOperator:
        return .prefixOperator
      case .postfixOperator:
        return .postfixOperator
      }
    }
  }
}

extension InitializerDeclSyntax {
  enum OptionalMarkOptions: TokenSpecSet {
    case postfixQuestionMark
    case infixQuestionMark
    case exclamationMark
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.postfixQuestionMark):
        self = .postfixQuestionMark
      case TokenSpec(.infixQuestionMark):
        self = .infixQuestionMark
      case TokenSpec(.exclamationMark):
        self = .exclamationMark
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMark
      case .infixQuestionMark:
        return .infixQuestionMark
      case .exclamationMark:
        return .exclamationMark
      }
    }
  }
}

extension KeyPathOptionalComponentSyntax {
  enum QuestionOrExclamationMarkOptions: TokenSpecSet {
    case postfixQuestionMark
    case exclamationMark
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.postfixQuestionMark):
        self = .postfixQuestionMark
      case TokenSpec(.exclamationMark):
        self = .exclamationMark
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMark
      case .exclamationMark:
        return .exclamationMark
      }
    }
  }
}

extension KeyPathPropertyComponentSyntax {
  enum IdentifierOptions: TokenSpecSet {
    case identifier
    case `self`
    case `Self`
    case `init`
    case dollarIdentifier
    case binaryOperator
    case integerLiteral
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.`self`):
        self = .`self`
      case TokenSpec(.`Self`):
        self = .`Self`
      case TokenSpec(.`init`):
        self = .`init`
      case TokenSpec(.dollarIdentifier):
        self = .dollarIdentifier
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      case TokenSpec(.integerLiteral):
        self = .integerLiteral
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .`self`:
        return .keyword(.`self`)
      case .`Self`:
        return .keyword(.`Self`)
      case .`init`:
        return .keyword(.`init`)
      case .dollarIdentifier:
        return .dollarIdentifier
      case .binaryOperator:
        return .binaryOperator
      case .integerLiteral:
        return .integerLiteral
      }
    }
  }
}

extension LayoutRequirementSyntax {
  enum LayoutConstraintOptions: TokenSpecSet {
    case _Trivial
    case _TrivialAtMost
    case _UnknownLayout
    case _RefCountedObject
    case _NativeRefCountedObject
    case _Class
    case _NativeClass
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(._Trivial):
        self = ._Trivial
      case TokenSpec(._TrivialAtMost):
        self = ._TrivialAtMost
      case TokenSpec(._UnknownLayout):
        self = ._UnknownLayout
      case TokenSpec(._RefCountedObject):
        self = ._RefCountedObject
      case TokenSpec(._NativeRefCountedObject):
        self = ._NativeRefCountedObject
      case TokenSpec(._Class):
        self = ._Class
      case TokenSpec(._NativeClass):
        self = ._NativeClass
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case ._Trivial:
        return .keyword(._Trivial)
      case ._TrivialAtMost:
        return .keyword(._TrivialAtMost)
      case ._UnknownLayout:
        return .keyword(._UnknownLayout)
      case ._RefCountedObject:
        return .keyword(._RefCountedObject)
      case ._NativeRefCountedObject:
        return .keyword(._NativeRefCountedObject)
      case ._Class:
        return .keyword(._Class)
      case ._NativeClass:
        return .keyword(._NativeClass)
      }
    }
  }
}

extension MemberTypeIdentifierSyntax {
  enum NameOptions: TokenSpecSet {
    case identifier
    case `self`
    case `Self`
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.`self`):
        self = .`self`
      case TokenSpec(.`Self`):
        self = .`Self`
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .`self`:
        return .keyword(.`self`)
      case .`Self`:
        return .keyword(.`Self`)
      }
    }
  }
}

extension MetatypeTypeSyntax {
  enum MetatypeSpecifierOptions: TokenSpecSet {
    case `Type`
    case `Protocol`
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.`Type`):
        self = .`Type`
      case TokenSpec(.`Protocol`):
        self = .`Protocol`
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .`Type`:
        return .keyword(.`Type`)
      case .`Protocol`:
        return .keyword(.`Protocol`)
      }
    }
  }
}

extension MoveExprSyntax {
  enum ConsumeKeywordOptions: TokenSpecSet {
    case _move
    case consume
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(._move):
        self = ._move
      case TokenSpec(.consume):
        self = .consume
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case ._move:
        return .keyword(._move)
      case .consume:
        return .keyword(.consume)
      }
    }
  }
}

extension MultipleTrailingClosureElementSyntax {
  enum LabelOptions: TokenSpecSet {
    case identifier
    case wildcard
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }
  }
}

extension OperatorDeclSyntax {
  enum FixitySpecifierOptions: TokenSpecSet {
    case prefix
    case postfix
    case infix
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.prefix):
        self = .prefix
      case TokenSpec(.postfix):
        self = .postfix
      case TokenSpec(.infix):
        self = .infix
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .prefix:
        return .keyword(.prefix)
      case .postfix:
        return .keyword(.postfix)
      case .infix:
        return .keyword(.infix)
      }
    }
  }
}

extension OperatorDeclSyntax {
  enum IdentifierOptions: TokenSpecSet {
    case binaryOperator
    case prefixOperator
    case postfixOperator
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      case TokenSpec(.prefixOperator):
        self = .prefixOperator
      case TokenSpec(.postfixOperator):
        self = .postfixOperator
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .binaryOperator:
        return .binaryOperator
      case .prefixOperator:
        return .prefixOperator
      case .postfixOperator:
        return .postfixOperator
      }
    }
  }
}

extension OptionalBindingConditionSyntax {
  enum BindingSpecifierOptions: TokenSpecSet {
    case `let`
    case `var`
    case `inout`
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.`let`):
        self = .`let`
      case TokenSpec(.`var`):
        self = .`var`
      case TokenSpec(.`inout`):
        self = .`inout`
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .`let`:
        return .keyword(.`let`)
      case .`var`:
        return .keyword(.`var`)
      case .`inout`:
        return .keyword(.`inout`)
      }
    }
  }
}

extension PrecedenceGroupAssignmentSyntax {
  enum ValueOptions: TokenSpecSet {
    case `true`
    case `false`
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.`true`):
        self = .`true`
      case TokenSpec(.`false`):
        self = .`false`
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .`true`:
        return .keyword(.`true`)
      case .`false`:
        return .keyword(.`false`)
      }
    }
  }
}

extension PrecedenceGroupAssociativitySyntax {
  enum ValueOptions: TokenSpecSet {
    case left
    case right
    case none
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.left):
        self = .left
      case TokenSpec(.right):
        self = .right
      case TokenSpec(.none):
        self = .none
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .left:
        return .keyword(.left)
      case .right:
        return .keyword(.right)
      case .none:
        return .keyword(.none)
      }
    }
  }
}

extension PrecedenceGroupRelationSyntax {
  enum HigherThanOrLowerThanLabelOptions: TokenSpecSet {
    case higherThan
    case lowerThan
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.higherThan):
        self = .higherThan
      case TokenSpec(.lowerThan):
        self = .lowerThan
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .higherThan:
        return .keyword(.higherThan)
      case .lowerThan:
        return .keyword(.lowerThan)
      }
    }
  }
}

extension QualifiedDeclNameSyntax {
  enum NameOptions: TokenSpecSet {
    case identifier
    case `self`
    case `Self`
    case `init`
    case binaryOperator
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.`self`):
        self = .`self`
      case TokenSpec(.`Self`):
        self = .`Self`
      case TokenSpec(.`init`):
        self = .`init`
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .`self`:
        return .keyword(.`self`)
      case .`Self`:
        return .keyword(.`Self`)
      case .`init`:
        return .keyword(.`init`)
      case .binaryOperator:
        return .binaryOperator
      }
    }
  }
}

extension SameTypeRequirementSyntax {
  enum EqualityTokenOptions: TokenSpecSet {
    case binaryOperator
    case prefixOperator
    case postfixOperator
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      case TokenSpec(.prefixOperator):
        self = .prefixOperator
      case TokenSpec(.postfixOperator):
        self = .postfixOperator
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .binaryOperator:
        return .binaryOperator
      case .prefixOperator:
        return .prefixOperator
      case .postfixOperator:
        return .postfixOperator
      }
    }
  }
}

extension SimpleTypeIdentifierSyntax {
  enum NameOptions: TokenSpecSet {
    case identifier
    case `self`
    case `Self`
    case `Any`
    case wildcard
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.`self`):
        self = .`self`
      case TokenSpec(.`Self`):
        self = .`Self`
      case TokenSpec(.`Any`):
        self = .`Any`
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .`self`:
        return .keyword(.`self`)
      case .`Self`:
        return .keyword(.`Self`)
      case .`Any`:
        return .keyword(.`Any`)
      case .wildcard:
        return .wildcard
      }
    }
  }
}

extension StringLiteralExprSyntax {
  enum OpenQuoteOptions: TokenSpecSet {
    case stringQuote
    case multilineStringQuote
    case singleQuote
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.stringQuote):
        self = .stringQuote
      case TokenSpec(.multilineStringQuote):
        self = .multilineStringQuote
      case TokenSpec(.singleQuote):
        self = .singleQuote
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .stringQuote:
        return .stringQuote
      case .multilineStringQuote:
        return .multilineStringQuote
      case .singleQuote:
        return .singleQuote
      }
    }
  }
}

extension StringLiteralExprSyntax {
  enum CloseQuoteOptions: TokenSpecSet {
    case stringQuote
    case multilineStringQuote
    case singleQuote
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.stringQuote):
        self = .stringQuote
      case TokenSpec(.multilineStringQuote):
        self = .multilineStringQuote
      case TokenSpec(.singleQuote):
        self = .singleQuote
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .stringQuote:
        return .stringQuote
      case .multilineStringQuote:
        return .multilineStringQuote
      case .singleQuote:
        return .singleQuote
      }
    }
  }
}

extension TryExprSyntax {
  enum QuestionOrExclamationMarkOptions: TokenSpecSet {
    case postfixQuestionMark
    case exclamationMark
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.postfixQuestionMark):
        self = .postfixQuestionMark
      case TokenSpec(.exclamationMark):
        self = .exclamationMark
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMark
      case .exclamationMark:
        return .exclamationMark
      }
    }
  }
}

extension TupleExprElementSyntax {
  enum LabelOptions: TokenSpecSet {
    case identifier
    case wildcard
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }
  }
}

extension TupleTypeElementSyntax {
  enum NameOptions: TokenSpecSet {
    case identifier
    case wildcard
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }
  }
}

extension TupleTypeElementSyntax {
  enum SecondNameOptions: TokenSpecSet {
    case identifier
    case wildcard
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }
  }
}

extension UnresolvedAsExprSyntax {
  enum QuestionOrExclamationMarkOptions: TokenSpecSet {
    case postfixQuestionMark
    case exclamationMark
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.postfixQuestionMark):
        self = .postfixQuestionMark
      case TokenSpec(.exclamationMark):
        self = .exclamationMark
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMark
      case .exclamationMark:
        return .exclamationMark
      }
    }
  }
}

extension ValueBindingPatternSyntax {
  enum BindingSpecifierOptions: TokenSpecSet {
    case `let`
    case `var`
    case `inout`
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.`let`):
        self = .`let`
      case TokenSpec(.`var`):
        self = .`var`
      case TokenSpec(.`inout`):
        self = .`inout`
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .`let`:
        return .keyword(.`let`)
      case .`var`:
        return .keyword(.`var`)
      case .`inout`:
        return .keyword(.`inout`)
      }
    }
  }
}

extension VariableDeclSyntax {
  enum BindingSpecifierOptions: TokenSpecSet {
    case `let`
    case `var`
    case `inout`
    
    init?(lexeme: Lexer.Lexeme) {
      switch PrepareForKeywordMatch(lexeme) {
      case TokenSpec(.`let`):
        self = .`let`
      case TokenSpec(.`var`):
        self = .`var`
      case TokenSpec(.`inout`):
        self = .`inout`
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .`let`:
        return .keyword(.`let`)
      case .`var`:
        return .keyword(.`var`)
      case .`inout`:
        return .keyword(.`inout`)
      }
    }
  }
}
